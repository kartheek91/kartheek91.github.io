<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-02-25T21:11:23+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Learn By Doing</title><subtitle>This site is created to share my learnings.Please let me know if you have any doubts regarding my postings.</subtitle><entry><title type="html">Introduction to Runtime Fields in ElasticSearch</title><link href="http://localhost:4000/2021/02/25/introduction-to-runtime-fields-in-elasticsearch.html" rel="alternate" type="text/html" title="Introduction to Runtime Fields in ElasticSearch" /><published>2021-02-25T08:53:15+05:30</published><updated>2021-02-25T08:53:15+05:30</updated><id>http://localhost:4000/2021/02/25/introduction-to-runtime-fields-in-elasticsearch</id><content type="html" xml:base="http://localhost:4000/2021/02/25/introduction-to-runtime-fields-in-elasticsearch.html">&lt;p&gt;Hi, all today I wanted to share with you one of the most awaited topics since I started learning elastic search. We used to have a product called &lt;strong&gt;MyCareer.com&lt;/strong&gt; where we used elasticsearch and indexed around 20 million resumes. Every time due to the aggressive timelines and incremental development we are in a situation where we need to add a couple of properties to an existing index. Till now we have only one solution i.e adding new properties to the existing mapping, creating a new index based on the new mapping, and try to reindex the data by passing the source and destination index. It is a tedious job correct so that’s the reason elasticsearch came up with &lt;strong&gt;Data Streams&lt;/strong&gt; and  I will cover this topic in upcoming posts. In elasticsearch 7.11 release they came with a solution called Runtime Fields. Please make note that  it is available in  &lt;strong&gt;Beta&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Runtime Fields&lt;/strong&gt;: A runtime field is a field that is evaluated at query time. It enables us with the following features i.e.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add fields to existing documents without reindexing your data&lt;/li&gt;
  &lt;li&gt;Start working with your data without understanding how it’s structured&lt;/li&gt;
  &lt;li&gt;Override the value returned from an indexed field at query time&lt;/li&gt;
  &lt;li&gt;Define fields for a specific use without modifying the underlying schema&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Queries against runtime fields are considered expensive. If search.&lt;strong&gt;allow_expensive_queries is set to false&lt;/strong&gt;, expensive queries are not allowed and Elasticsearch will reject any queries against runtime fields.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Runtime fields aren’t indexed, adding a runtime field doesn’t increase the index size.&lt;/li&gt;
  &lt;li&gt;We can define runtime fields directly in the index mapping, saving storage costs and increasing ingestion speed.&lt;/li&gt;
  &lt;li&gt;When you define a runtime field, you can immediately use it in search requests, aggregations, filtering, and sorting.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt; :
																					&lt;em&gt;Queries&lt;/em&gt; against runtime fields can be expensive, so data that you commonly search or filter on should still be mapped to indexed fields. Runtime fields can also decrease search speed, even though your index size is smaller.&lt;/p&gt;

&lt;p&gt;Now let’s make our hands dirty by adding runtime fields.&lt;/p&gt;

&lt;p&gt;Creating sample &lt;strong&gt;employee&lt;/strong&gt; index:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PUT employee
{
  &quot;mappings&quot;: {
    &quot;dynamic&quot;: &quot;runtime&quot;,
    &quot;properties&quot;: {
      &quot;name&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;fields&quot;: {
          &quot;raw&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          }
        }
      },
      &quot;dob&quot;: {
        &quot;type&quot;: &quot;date&quot;,
        &quot;format&quot;: &quot;yyyy-MM-dd&quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now we will check the employee mapping&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_mapping
Output:
{
  &quot;employee&quot; : {
    &quot;mappings&quot; : {
      &quot;dynamic&quot; : &quot;runtime&quot;,
      &quot;properties&quot; : {
        &quot;dob&quot; : {
          &quot;type&quot; : &quot;date&quot;,
          &quot;format&quot; : &quot;yyyy-MM-dd&quot;
        },
        &quot;name&quot; : {
          &quot;type&quot; : &quot;text&quot;,
          &quot;fields&quot; : {
            &quot;raw&quot; : {
              &quot;type&quot; : &quot;keyword&quot;
            }
          }
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So now we try to insert a couple of sample documents into the employee index.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PUT employee/_doc/1
{
  &quot;name&quot;:&quot;Kiran Sangita&quot;,
  &quot;dob&quot;:&quot;1980-04-01&quot;,
  &quot;fullname&quot;:&quot;kiran appaji sangita&quot;,
  &quot;age&quot;:&quot;45&quot;
}
PUT employee/_doc/2
{
  &quot;name&quot;:&quot;Kartheek Gummaluri&quot;,
  &quot;dob&quot;:&quot;1991-12-28&quot;,
  &quot;fullname&quot;:&quot;Sai Srinivasa Kartheek Gummaluri&quot;,
  &quot;age&quot;:&quot;29&quot;
}
PUT employee/_doc/3
{
  &quot;name&quot;:&quot;Pavan Kumar&quot;,
  &quot;dob&quot;:&quot;1980-12-28&quot;,
  &quot;fullname&quot;:&quot;Pavan Arya&quot;,
  &quot;age&quot;:&quot;34&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we will check mapping again and we will see age, full name as runtime fields.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_mapping
Output: 
{
  &quot;employee&quot; : {
    &quot;mappings&quot; : {
      &quot;dynamic&quot; : &quot;runtime&quot;,
      &quot;runtime&quot; : {
        &quot;age&quot; : {
          &quot;type&quot; : &quot;keyword&quot;
        },
        &quot;fullname&quot; : {
          &quot;type&quot; : &quot;keyword&quot;
        }
      },
      &quot;properties&quot; : {
        &quot;dob&quot; : {
          &quot;type&quot; : &quot;date&quot;,
          &quot;format&quot; : &quot;yyyy-MM-dd&quot;
        },
        &quot;name&quot; : {
          &quot;type&quot; : &quot;text&quot;,
          &quot;fields&quot; : {
            &quot;raw&quot; : {
              &quot;type&quot; : &quot;keyword&quot;
            }
          }
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let’s write a small query to search documents having an age greater than 29.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_search
{
  &quot;query&quot;: {
    &quot;range&quot;: {
      &quot;age&quot;: {
        &quot;gt&quot;: 29
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Result:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;employee&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 1.0,
        &quot;_source&quot; : {
          &quot;name&quot; : &quot;Kiran Sangita&quot;,
          &quot;dob&quot; : &quot;1980-04-01&quot;,
          &quot;fullname&quot; : &quot;kiran appaji sangita&quot;,
          &quot;age&quot; : &quot;45&quot;
        }
      },
      {
        &quot;_index&quot; : &quot;employee&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;3&quot;,
        &quot;_score&quot; : 1.0,
        &quot;_source&quot; : {
          &quot;name&quot; : &quot;Pavan Kumar&quot;,
          &quot;dob&quot; : &quot;1980-12-28&quot;,
          &quot;fullname&quot; : &quot;Pavan Arya&quot;,
          &quot;age&quot; : &quot;34&quot;
        }
      }
    ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This way we simply queried using runtime field and as mentioned earlier this field is not indexed but still, we can retrieve the results.&lt;/p&gt;

&lt;p&gt;Now lets something new out of it like we can create the concatenation of two fields with a static string as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_search
{
  &quot;runtime_mappings&quot;: {
    &quot;concatenated_field&quot;: {
      &quot;type&quot;: &quot;keyword&quot;,
      &quot;script&quot;: {
        &quot;source&quot;: &quot;emit(doc['fullname'].value + '_' +  doc['age'].value.toString())&quot;
      }
    }
  },
  &quot;fields&quot;: [
    &quot;concatenated_field&quot;
  ],
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;concatenated_field&quot;: &quot;kiran appaji sangita_45&quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We defined the field &lt;strong&gt;concatenated_field&lt;/strong&gt; in the runtime_mappings section. We used a short Painless script that defines how the value of concatenated_field will be calculated per document (using + to indicate concatenation of the value of the full name field with the static string ‘:’ and the value of the age field). We then used the field concatenated_field in the query. When defining a Painless script to use with runtime fields, you must include emit to return calculated values.&lt;/p&gt;

&lt;p&gt;Result:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;employee&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 1.0,
        &quot;_source&quot; : {
          &quot;name&quot; : &quot;Kiran Sangita&quot;,
          &quot;dob&quot; : &quot;1980-04-01&quot;,
          &quot;fullname&quot; : &quot;kiran appaji sangita&quot;,
          &quot;age&quot; : &quot;45&quot;
        },
        &quot;fields&quot; : {
          &quot;concatenated_field&quot; : [
            &quot;kiran appaji sangita_45&quot;
          ]
        }
      }
    ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If we find that &lt;strong&gt;concatenated_field&lt;/strong&gt; is a field that we want to use in multiple queries without having to define it per query, we can simply add it to the mapping by making the call:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; PUT employee/_mapping
 {
   &quot;runtime&quot;: {
     &quot;concatenated_field&quot;: {
       &quot;type&quot;: &quot;keyword&quot;,
        &quot;script&quot;: {
        &quot;source&quot;: &quot;emit(doc['fullname'].value + '_' +  doc['age'].value.toString())&quot;
      }
     } 
   } 
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now we will again check the mappings of the employee index, this time you will see &lt;strong&gt;concatenated_field&lt;/strong&gt; will be added in the mapping.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Output&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_mapping
{
  &quot;employee&quot; : {
    &quot;mappings&quot; : {
      &quot;dynamic&quot; : &quot;runtime&quot;,
      &quot;runtime&quot; : {
        &quot;age&quot; : {
          &quot;type&quot; : &quot;keyword&quot;
        },
        &quot;concatenated_field&quot; : {
          &quot;type&quot; : &quot;keyword&quot;,
          &quot;script&quot; : {
            &quot;source&quot; : &quot;emit(doc['fullname'].value + '_' +  doc['age'].value.toString())&quot;,
            &quot;lang&quot; : &quot;painless&quot;
          }
        },
        &quot;fullname&quot; : {
          &quot;type&quot; : &quot;keyword&quot;
        }
      },
      &quot;properties&quot; : {
        &quot;dob&quot; : {
          &quot;type&quot; : &quot;date&quot;,
          &quot;format&quot; : &quot;yyyy-MM-dd&quot;
        },
        &quot;name&quot; : {
          &quot;type&quot; : &quot;text&quot;,
          &quot;fields&quot; : {
            &quot;raw&quot; : {
              &quot;type&quot; : &quot;keyword&quot;
            }
          }
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And then the query does not have to include the definition of the field, for example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;concatenated_field&quot;: &quot;kiran appaji sangita_45&quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now let’s see the result as I mentioned earlier we will not see &lt;strong&gt;concatenated_field&lt;/strong&gt; in the source document.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Output&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; {
        &quot;_index&quot; : &quot;employee&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 1.0,
        &quot;_source&quot; : {
          &quot;name&quot; : &quot;Kiran Sangita&quot;,
          &quot;dob&quot; : &quot;1980-04-01&quot;,
          &quot;fullname&quot; : &quot;kiran appaji sangita&quot;,
          &quot;age&quot; : &quot;45&quot;
        }
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If we want to see &lt;strong&gt;concatenated_field&lt;/strong&gt; then we need to specify implicitly in the &lt;strong&gt;fields&lt;/strong&gt; section.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET employee/_search
{
  &quot;fields&quot;: [
    &quot;concatenated_field&quot;
  ],
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;concatenated_field&quot;: &quot;kiran appaji sangita_45&quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Output&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;employee&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 1.0,
        &quot;_source&quot; : {
          &quot;name&quot; : &quot;Kiran Sangita&quot;,
          &quot;dob&quot; : &quot;1980-04-01&quot;,
          &quot;fullname&quot; : &quot;kiran appaji sangita&quot;,
          &quot;age&quot; : &quot;45&quot;
        },
        &quot;fields&quot; : {
          &quot;concatenated_field&quot; : [
            &quot;kiran appaji sangita_45&quot;
          ]
        }
      }
    ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is how we can make use of &lt;strong&gt;Runtime Fields&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Thanks &lt;br /&gt;
&lt;strong&gt;&lt;em&gt;Kartheek Gummaluri&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><category term="ELasticSearch" /><summary type="html">Hi, all today I wanted to share with you one of the most awaited topics since I started learning elastic search. We used to have a product called MyCareer.com where we used elasticsearch and indexed around 20 million resumes. Every time due to the aggressive timelines and incremental development we are in a situation where we need to add a couple of properties to an existing index. Till now we have only one solution i.e adding new properties to the existing mapping, creating a new index based on the new mapping, and try to reindex the data by passing the source and destination index. It is a tedious job correct so that’s the reason elasticsearch came up with Data Streams and I will cover this topic in upcoming posts. In elasticsearch 7.11 release they came with a solution called Runtime Fields. Please make note that it is available in Beta</summary></entry><entry><title type="html">Painless Scripting Language-Series-1</title><link href="http://localhost:4000/2021/02/07/painless-scripting-language-series-1.html" rel="alternate" type="text/html" title="Painless Scripting Language-Series-1" /><published>2021-02-07T13:15:20+05:30</published><updated>2021-02-07T13:15:20+05:30</updated><id>http://localhost:4000/2021/02/07/painless-scripting-language-series-1</id><content type="html" xml:base="http://localhost:4000/2021/02/07/painless-scripting-language-series-1.html">&lt;p&gt;Today we will learn about very intresting scripting language called &lt;strong&gt;Painless&lt;/strong&gt;. So let’s jump directy into the topic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Painless:&lt;/em&gt;&lt;/strong&gt;
It is a simple, secure scripting language designed specifically for use with Elasticsearch. It is the default scripting language for Elasticsearch and can safely be used for inline and stored scripts.In fact, most Painless scripts are also valid Groovy, and simple Groovy scripts are typically valid Painless.&lt;/p&gt;

&lt;p&gt;Painless scripts are parsed and compiled using the ANTLR4 and ASM libraries. Painless scripts are compiled directly into Java byte code and executed against a standard Java Virtual Machine.
You can use Painless anywhere scripts are used in Elasticsearch. Painless provides:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It is fast performance.&lt;/li&gt;
  &lt;li&gt;Safety: Fine-grained allowlist with method call/field granularity.&lt;/li&gt;
  &lt;li&gt;Optional typing: Variables and parameters can use explicit types or the dynamic def type.&lt;/li&gt;
  &lt;li&gt;Syntax: Extends a subset of Java’s syntax to provide additional scripting language features.&lt;/li&gt;
  &lt;li&gt;Optimizations: Designed specifically for Elasticsearch scripting.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Painless Evolution:&lt;/em&gt;&lt;/strong&gt;
Since the earlier versions of ES, it supported scripting, but the scripting language has evolved over the ES releases. Starting with MVEL prior version 1.4, Groovy (post version 1.4), and now the latest entry &lt;strong&gt;&lt;em&gt;Painless&lt;/em&gt;&lt;/strong&gt;  starting ES 5.0, the scripting in ES has evolved. A key reason for this evolution is for the above mentioned features.&lt;/p&gt;

&lt;p&gt;Prior the release of &lt;strong&gt;&lt;em&gt;Painless&lt;/em&gt;&lt;/strong&gt; in ES 5.0, the majority of the security vulnerabilities that were reported in ES had to deal with vulnerabilities due to the scripting. Painless scripting language addresses these issues and is more secure, and faster than its predecessors. Starting ES 5.0, “Painless” is the default scripting language and its syntax is similar to &lt;strong&gt;Groovy&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This blog takes it a level further and explains the various usages of scripting that would be very handy.&lt;/p&gt;

&lt;p&gt;Before we can start using the scripts lets understand the syntax of scripts in ES.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;script&quot;: {
 &quot;lang&quot;: &quot;...&quot;, 
 &quot;inline&quot; | &quot;stored&quot;: &quot;...&quot;,
 &quot;params&quot;: { ... }
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As shown above, the script syntax consists of three parts:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The language the script is written in, which defaults to painless.&lt;/li&gt;
  &lt;li&gt;The script itself which may be specified as source for an inline script or id for a stored script.&lt;/li&gt;
  &lt;li&gt;Any named parameters that should be passed into the script.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s illustrate how Painless works by loading some student stats into an Elasticsearch index:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PUT student/_bulk?refresh
{&quot;index&quot;:{&quot;_id&quot;:1}}
{&quot;first_name&quot;:&quot;kiran&quot;,&quot;last_name&quot;:&quot;sangita&quot;,&quot;score&quot;:[9,27,1],&quot;dob&quot;:&quot;1980/08/13&quot;}
{&quot;index&quot;:{&quot;_id&quot;:2}}
{&quot;first_name&quot;:&quot;kartheek&quot;,&quot;last_name&quot;:&quot;gummaluri&quot;,&quot;score&quot;:[19,37,12],&quot;dob&quot;:&quot;1991/12/28&quot;}
{&quot;index&quot;:{&quot;_id&quot;:3}}
{&quot;first_name&quot;:&quot;pavan&quot;,&quot;last_name&quot;:&quot;arya&quot;,&quot;score&quot;:[22,12,34],&quot;dob&quot;:&quot;1989/01/22&quot;}
{&quot;index&quot;:{&quot;_id&quot;:4}}
{&quot;first_name&quot;:&quot;murali&quot;,&quot;last_name&quot;:&quot;sangita&quot;,&quot;score&quot;:[10,2,44],&quot;dob&quot;:&quot;1990/04/15&quot;}
{&quot;index&quot;:{&quot;_id&quot;:5}}
{&quot;first_name&quot;:&quot;prudwi&quot;,&quot;last_name&quot;:&quot;seeramreddi&quot;,&quot;score&quot;:[12,22,14],&quot;dob&quot;:&quot;1991/08/17&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Accessing Doc Values from Painless:&lt;/em&gt;&lt;/strong&gt;
Document values can be accessed from a Map named doc.&lt;/p&gt;

&lt;p&gt;For example, the following script calculates a student’s total score who name start’s with letter &lt;strong&gt;K&lt;/strong&gt;. This example uses a strongly typed int and a for loop.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET student/_search
{
  &quot;query&quot;: {
    &quot;prefix&quot;: {
      &quot;first_name&quot;: {
        &quot;value&quot;: &quot;k&quot;
      }
    }
  },
  &quot;script_fields&quot;: {
    &quot;total_score&quot;: {
      &quot;script&quot;: {
        &quot;lang&quot;: &quot;painless&quot;,
        &quot;source&quot;: &quot;&quot;&quot;
          int total = 0;
          for (int i = 0; i &amp;lt; doc['score'].length; ++i) {
            total += doc['score'][i];
          
          }
          return total;
        &quot;&quot;&quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Result&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;student&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 1.0,
        &quot;fields&quot; : {
          &quot;total_score&quot; : [
            37
          ]
        }
      },
      {
        &quot;_index&quot; : &quot;student&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;2&quot;,
        &quot;_score&quot; : 1.0,
        &quot;fields&quot; : {
          &quot;total_score&quot; : [
            68
          ]
        }
      }
    ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The following example uses a Painless script to sort the students by their combined first and last names. The names are accessed using doc[‘first_name’].keyword.value and doc[‘last_name’].keyword.value.
&lt;strong&gt;&lt;em&gt;Query&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET student/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  },
  &quot;sort&quot;: {
    &quot;_script&quot;: {
      &quot;type&quot;: &quot;string&quot;,
      &quot;order&quot;: &quot;asc&quot;,
      &quot;script&quot;: {
        &quot;lang&quot;: &quot;painless&quot;,
        &quot;source&quot;: &quot;doc['first_name.keyword'].value + ' ' + doc['last_name.keyword'].value&quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Result&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;student&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;2&quot;,
        &quot;_score&quot; : null,
        &quot;_source&quot; : {
          &quot;first_name&quot; : &quot;kartheek&quot;,
          &quot;last_name&quot; : &quot;gummaluri&quot;,
          &quot;score&quot; : [
            19,
            37,
            12
          ],
          &quot;dob&quot; : &quot;1991/12/28&quot;
        },
        &quot;sort&quot; : [
          &quot;kartheek gummaluri&quot;
        ]
      },
      {
        &quot;_index&quot; : &quot;student&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : null,
        &quot;_source&quot; : {
          &quot;first_name&quot; : &quot;kiran&quot;,
          &quot;last_name&quot; : &quot;sangita&quot;,
          &quot;score&quot; : [
            9,
            27,
            1
          ],
          &quot;dob&quot; : &quot;1980/08/13&quot;
        },
        &quot;sort&quot; : [
          &quot;kiran sangita&quot;
        ]
      },....]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Missing Values&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now let learn how to query if we have missing values either in last_name, first_name.doc[‘field’].value throws an exception if the field is missing in a document.&lt;/p&gt;

&lt;p&gt;To check if a document is missing a value, you can call doc[‘field’].size() == 0. So let’s add another document in the &lt;strong&gt;student&lt;/strong&gt; index.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PUT student/_doc/6
{&quot;first_name&quot;:&quot;bala&quot;,&quot;score&quot;:[11,33,12],&quot;dob&quot;:&quot;1971/04/21&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you observe in the above mentioned document we haven’t specified &lt;strong&gt;last_name&lt;/strong&gt; and now let’s re-run the above mentioned query which concatenates first_name and last_name.&lt;/p&gt;

&lt;p&gt;After executing the above mentioned query we end up with run time error.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
        &quot;shard&quot;: 0,
        &quot;index&quot;: &quot;student&quot;,
        &quot;node&quot;: &quot;993H1-V5Qk6Qc2nOoZ0iuw&quot;,
        &quot;reason&quot;: {
          &quot;type&quot;: &quot;script_exception&quot;,
          &quot;reason&quot;: &quot;runtime error&quot;,
          &quot;script_stack&quot;: [
            &quot;org.elasticsearch.index.fielddata.ScriptDocValues$Strings.get(ScriptDocValues.java:496)&quot;,
            &quot;org.elasticsearch.index.fielddata.ScriptDocValues$Strings.getValue(ScriptDocValues.java:503)&quot;,
            &quot;doc['first_name.keyword'].value + ' ' + doc['last_name.keyword'].value&quot;,
            &quot;                                                                ^---- HERE&quot;
          ],
          &quot;script&quot;: &quot;doc['first_name.keyword'].value + ' ' + doc['last_name.keyword'].value&quot;,
          &quot;lang&quot;: &quot;painless&quot;,
          &quot;caused_by&quot;: {
            &quot;type&quot;: &quot;illegal_state_exception&quot;,
            &quot;reason&quot;: &quot;A document doesn't have a value for a field! Use doc[&amp;lt;field&amp;gt;].size()==0 to check if a document is missing a field!&quot;
          }
        }
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you observe the reason session it clearly saying that we are trying to access document which doesn’t have a value for a field. It is also providing recommendation for us.Now let’s re-write the query.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
GET student/_search
{
  &quot;query&quot;: {
   &quot;match_all&quot;: {}
  },
 &quot;script_fields&quot;: {
   &quot;full_name&quot;: {
     &quot;script&quot;: {
       &quot;lang&quot;: &quot;painless&quot;,
        &quot;source&quot;: &quot;&quot;&quot;if(doc['last_name.keyword'].size()&amp;gt;0 &amp;amp;&amp;amp; doc['first_name.keyword'].size()&amp;gt;0) {  return doc['first_name.keyword'].value + ' ' + doc['last_name.keyword'].value}&quot;&quot;&quot;
       
     }
   }
 }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This way we can overcome the above mentioned exception.Finally I will conclude with an important information and we can learn in depth in upcoming blogs.&lt;/p&gt;

&lt;p&gt;The first time Elasticsearch sees a new script, it compiles it and stores the compiled version in a cache. Compilation can be a heavy process.&lt;/p&gt;

&lt;p&gt;If you need to pass variables into the script, you should pass them in as named params instead of hard-coding values into the script itself. We will try to learn these topic in upcoming blog post with an real time example.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;Kartheek Gummaluri&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><category term="ELasticSearch" /><category term="Painless" /><summary type="html">Today we will learn about very intresting scripting language called Painless. So let’s jump directy into the topic.</summary></entry><entry><title type="html">MY PLANS FOR YEAR 2021</title><link href="http://localhost:4000/2021/01/01/my-plans-for-year-2021.html" rel="alternate" type="text/html" title="MY PLANS FOR YEAR 2021" /><published>2021-01-01T22:00:46+05:30</published><updated>2021-01-01T22:00:46+05:30</updated><id>http://localhost:4000/2021/01/01/my-plans-for-year-2021</id><content type="html" xml:base="http://localhost:4000/2021/01/01/my-plans-for-year-2021.html">&lt;h2 id=&quot;happy-new-year-2021&quot;&gt;Happy New Year 2021&lt;/h2&gt;
&lt;p&gt;First of all, Thank you for all  following my blog and showing interest in reading my articles. In this blog post, I would like to discuss my plans for the year 2021. I’ll work hard to accomplish all my goals mentioned here and share my learnings.&lt;/p&gt;

&lt;h3 id=&quot;here-is-a-brief-list-of-todos-that-i-am-planning-to-accomplish-in-2021&quot;&gt;Here is a brief list of todo’s that I am planning to accomplish in 2021&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Increase my blogging frequency&lt;/strong&gt;: I started blogging since 2 years, but i was like passive participant and I used to create posts perodically due to my work. I understand the value and importance of contributing to the community. So this year I again want to get in touch with developer communities and my fellow developers. So my target for this year and upcoming years is to post at least one article( of course useful ones) per week.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Learn Apache Kafka in depth&lt;/strong&gt;:&lt;strong&gt;A&lt;/strong&gt;pache Kafka is a community distributed event streaming platform capable of handling trillions of events a day. Initially conceived as a messaging queue, Kafka is based on an abstraction of a distributed commit log. Since being created and open sourced by LinkedIn in 2011, Kafka has quickly evolved from messaging queue to a full-fledged event streaming platform.I have hands-on experience but I need to get my hands dirty in depth on  KsqlDb, Kafka-Api, Kafka-Cluser Architecture.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use at least one programming language other than the ones which I frequently use&lt;/strong&gt;: Since 4  years I’m  working on Microsoft technologies and NoSql databases like ELK stack, Couchbase and MongoDb, I did write code in other programming languages like “Python” and did develop a good project using these technologies. But I was like a Nightwatchman ( If you follow cricket, especially test matches) working on these technologies. Of course, I strongly believe that Programming language should never be a barrier to implement ideas or thoughts for a good developer. At any given point of time, I believe that a good developer should be capable of writing code in any programming language. But of course there is a slight difference between writing code in a new programming language and excelling in that programming language. So I decided to learn and excel in “Python”. Reason for choosing Python is for 4 years I am using C# which is statically typed and I would like to the taste the dynamic nature of python now. Also, I am planning to learn about data engineering, Python provides some packages in those areas like NumPy, SciPi and many more. Also, another reason is I would like to explore Apache Spark and using PySpark I’ll be able to write map-reduce functions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And the list is never ending but I would like to focus on these technologies and goals for this year and If time permits, I’ll be focusing on some other topics like exploring AWS cloud solutions such as AWS Athena, Azure cloud solutions such as Application Gateways, Azure Bastion etc and Red Hat OpenShift which is an open source container application platform based on the Kubernetes container orchestraton.&lt;/p&gt;

&lt;p&gt;Last but on the least I would like to thank my well wishers, mentors who has always been my constant support starting with my mentors Kiran Sangita, Siva AVKD, Pavan Arya, Sumath AWS, Aravind ELK and list continues……….&lt;/p&gt;

&lt;p&gt;And once again I wish everyone a Happy New Year. Please do post your valuable suggestions, questions, and learnings, and let’s try to learn as much as possible this year.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;Kartheek Gummaluri&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Happy New Year 2021 First of all, Thank you for all following my blog and showing interest in reading my articles. In this blog post, I would like to discuss my plans for the year 2021. I’ll work hard to accomplish all my goals mentioned here and share my learnings.</summary></entry><entry><title type="html">Apache-NiFi-Series-1 GetFile and PutFile Processors</title><link href="http://localhost:4000/2020/08/03/apache-nifi-series-1-getfile-and-putfile-processors.html" rel="alternate" type="text/html" title="Apache-NiFi-Series-1 GetFile and PutFile Processors" /><published>2020-08-03T21:00:06+05:30</published><updated>2020-08-03T21:00:06+05:30</updated><id>http://localhost:4000/2020/08/03/apache-nifi-series-1-getfile-and-putfile-processors</id><content type="html" xml:base="http://localhost:4000/2020/08/03/apache-nifi-series-1-getfile-and-putfile-processors.html">&lt;h1 id=&quot;apache-nifi-getfile-and-putfile-processors&quot;&gt;Apache NiFi GetFile and PutFile Processors&lt;/h1&gt;
&lt;p&gt;Hi, In this post I’ll discuss on how to leverage  &lt;strong&gt;&lt;em&gt;Get and Put File Processors&lt;/em&gt;&lt;/strong&gt; using  &lt;strong&gt;&lt;em&gt;Apache-NiF&lt;/em&gt;i&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Apache NiFi&lt;/em&gt;&lt;/strong&gt; is a real time data ingestion platform, which can transfer and manage data transfer between different sources and destination systems. It supports a wide variety of data formats like logs, geo location data, social feeds, etc. It also supports many protocols like SFTP, HDFS, and KAFKA, etc. This support to wide variety of data sources and protocols making this platform popular in many IT organizations.&lt;/p&gt;

&lt;p&gt;So we will take two processors i.e. GetFile Processor, PutFile Processor and will try to establish relationship between two procesors. Our goal is to move the files from one location to another.&lt;/p&gt;

&lt;h1 id=&quot;getfile-processor&quot;&gt;GetFile Processor&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;GetFile Processor&lt;/em&gt;&lt;/strong&gt;  is used to fetch files of a specific format from a specific directory. It also provides other options to user for more control on fetching. We will discuss it in properties section below.So now we will add this processor.&lt;/p&gt;

&lt;h1 id=&quot;steps-to-add-this-getfile-processor-to-the-workspace&quot;&gt;Steps to add this GetFile Processor to the WorkSpace&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Drag the processor icon from the  menu and you will see the following window.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/addProcessor.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Now we need to add GetFileProcessor, go to the top right corner and  in filter box type &lt;strong&gt;GetFile&lt;/strong&gt; and  double click on the result then you willl processor getting added to the workspace.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/getFile1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Now we will set  &lt;strong&gt;&lt;em&gt;GetFile Properties&lt;/em&gt;&lt;/strong&gt;  which is important and without we can’t start the processor.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/getFile_Properties.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So the proeprties which are in bold are the mandatory properties, we need to set values for those properties without which we can’t      start the processor. Let’s fill the properties and click on the &lt;strong&gt;Apply&lt;/strong&gt; button.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/getFile_Configuration.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;putfile-processor&quot;&gt;PutFile Processor&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;PutFile Processor&lt;/em&gt;&lt;/strong&gt; The PutFile processor is used to store the file from the data flow to a specific location. We will discuss it in properties section below.So now we will add this processor.&lt;/p&gt;

&lt;h1 id=&quot;steps-to-add-this-putfile-processor-to-the-workspace&quot;&gt;Steps to add this PutFile Processor to the WorkSpace&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We can replicate the above mentioned steps and try to  filter it out by &lt;strong&gt;PutFilter&lt;/strong&gt; double click on it and you will end up with this screen.
&lt;img src=&quot;/getFile_putFile.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;So the proeprties which are in bold are the mandatory properties, we need to set values for those properties without which we can’t      start the processor. Let’s fill the properties in properties tab and don’t forget to check  &lt;strong&gt;&lt;em&gt;sucess and failure&lt;/em&gt;&lt;/strong&gt;  in setting tab.&lt;/li&gt;
  &lt;li&gt;Now click  &lt;strong&gt;Apply&lt;/strong&gt; button.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/putfile_property.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;create-connection&quot;&gt;Create Connection&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Now we will create connection between two processors and we will end up with the following screen.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/createconnection.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Now we go to the input directory and I have copied &lt;strong&gt;100 pdf  files&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/input_directory.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Now we are ready to start the processors, in order to start the processors right click on the workspace and click start. Then we are are good to go. For our understanding i will start processors individually.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/input_processor_start.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So now we will see 100 items in the queue.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/quee100.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Now we will start &lt;strong&gt;Put File Processor&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/putoutput.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Finally now we will check  in the &lt;strong&gt;Output Directory&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/output_direcotry.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So this how we will leverage &lt;strong&gt;GetFile and PutFile Processors&lt;/strong&gt;  using &lt;strong&gt;Apache NiFi&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;Kartheek Gummaluri&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><category term="APACHE" /><category term="NIFI" /><summary type="html">Apache NiFi GetFile and PutFile Processors Hi, In this post I’ll discuss on how to leverage Get and Put File Processors using Apache-NiFi</summary></entry><entry><title type="html">Convert Emojis to text and Emoticons to text using emot package</title><link href="http://localhost:4000/dev/2020/08/03/convert-emojis-to-text-and-emoticons-to-text-using-emot-package.html" rel="alternate" type="text/html" title="Convert Emojis to text and Emoticons to text using emot package" /><published>2020-08-03T17:47:06+05:30</published><updated>2020-08-03T17:47:06+05:30</updated><id>http://localhost:4000/dev/2020/08/03/convert-emojis-to-text-and-emoticons-to-text-using-emot-package</id><content type="html" xml:base="http://localhost:4000/dev/2020/08/03/convert-emojis-to-text-and-emoticons-to-text-using-emot-package.html">&lt;p&gt;Here I will explain you how to convert emojis and emoticons to text.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data_path = &quot;D:/nlp/HelperCodes/&quot;
import sys
import re
import emot

sys.path.append(data_path)
from text_prep_config import UNICODE_EMO, EMOTICONS

def convert_emojis(text):
    for emot in UNICODE_EMO:
#        print(&quot;_&quot;.join(UNICODE_EMO[emot].replace(&quot;,&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;).split()))
        text = re.sub(r'(' + emot + ')', &quot;_&quot;.join(UNICODE_EMO[emot].replace(&quot;,&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;).split()), text)
    return text

def convert_emoticons(text):
    for emot in EMOTICONS:
        text = re.sub(u'('+emot+')', &quot;_&quot;.join(EMOTICONS[emot].replace(&quot;,&quot;,&quot;&quot;).split()), text)
    return text

def remove_emoji(string):
  emoji_pattern = re.compile(&quot;[&quot;
                       u&quot;\U0001F600-\U0001F64F&quot;  # emoticons
                       u&quot;\U0001F300-\U0001F5FF&quot;  # symbols &amp;amp; pictographs
                       u&quot;\U0001F680-\U0001F6FF&quot;  # transport &amp;amp; map symbols
                       u&quot;\U0001F1E0-\U0001F1FF&quot;  # flags (iOS)
                       u&quot;\U00002702-\U000027B0&quot;
                       u&quot;\U000024C2-\U0001F251&quot;
                       &quot;]+&quot;, flags=re.UNICODE)
  return emoji_pattern.sub(r'', string)

def remove_emoticons(text):
    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')
    return emoticon_pattern.sub(r'', text)

emoticons_text = &quot;Hello :-) :-)&quot;
emojis_text = &quot;Game is on 🔥&quot;

print(&quot;CONVERTING Emojis to Text:\n*\nInput: &quot; + emojis_text +  &quot;\n&quot;+ &quot;Output: &quot; + convert_emojis(emojis_text) + &quot;\n*&quot;)
print(&quot;CONVERTING Emoticons to Text:\n*\nInput: &quot; + emoticons_text +  &quot; \n&quot; + &quot;Output: &quot; + convert_emoticons(emoticons_text) + &quot;\n*&quot;)
print(&quot;Removing Emoticons in the Text:\n*\nInput: &quot; + emoticons_text +  &quot; \n&quot; + &quot;Output: &quot; + remove_emoticons(emoticons_text)+ &quot;\n*&quot;)
print(&quot;Removing  Emojis in the Text:\nInput: &quot; + emojis_text +  &quot; \n&quot; + &quot;Output: &quot; + remove_emoji(emojis_text))

#Now we will use emot package that is designed by NeelShah

print(emot.emoji(emojis_text))
print(emot.emoticons(emoticons_text))

for code in emot.UNICODE_EMO:
    print( code  + emot.UNICODE_EMO[code] + &quot;\n&quot;)
    
for code in emot.EMOTICONS:
    print( code  + &quot;=&quot; +  emot.EMOTICONS[code] + &quot;\n&quot;)**
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So here we  wrote a method called &lt;strong&gt;convert_emojis&lt;/strong&gt; where it will accept a string and you will get the text corresponding to emoji and here is the output.&lt;/p&gt;</content><author><name></name></author><category term="Dev" /><category term="Python" /><summary type="html">Here I will explain you how to convert emojis and emoticons to text. ``` data_path = “D:/nlp/HelperCodes/” import sys import re import emot</summary></entry><entry><title type="html">Introduction to “Did You Mean “ feature in ElasticSearch</title><link href="http://localhost:4000/2019/04/20/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Introduction to “Did You Mean “ feature in ElasticSearch" /><published>2019-04-20T13:12:15+05:30</published><updated>2019-04-20T13:12:15+05:30</updated><id>http://localhost:4000/2019/04/20/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/2019/04/20/welcome-to-jekyll.html">&lt;p&gt;In this post I will explain you the different types of suggestors that elasticsearch is providing and I will give you brief about “Completion Suggestor”.&lt;/p&gt;

&lt;p&gt;There are 4 types of suggestors&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Term Suggestor&lt;/li&gt;
  &lt;li&gt;Phrase Suggestor&lt;/li&gt;
  &lt;li&gt;Completion Suggestor&lt;/li&gt;
  &lt;li&gt;Context Suggestor&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So in recent times I have used a completion suggestor in one of my projects.The completion suggester provides auto-complete/search-as-you-type functionality. This is a navigational feature to guide users to relevant results as they are typing, improving search precision. It is not meant for spell correction or did-you-mean functionality like the term or phrase suggester&lt;/p&gt;

&lt;p&gt;I will expalin with a small example in understand better and here is the sample mapping&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPUT &quot;http://localhost:9200/sample&quot; -H 'Content-Type: application/json' -d'
{
  &quot;mappings&quot;: {
    &quot;doc&quot;: {
      &quot;properties&quot;: {
        &quot;namesuggest&quot;: {
          &quot;type&quot;: &quot;completion&quot;,
          &quot;analyzer&quot;: &quot;standard&quot;,
          &quot;preserve_separators&quot;: true,
          &quot;preserve_position_increments&quot;: true,
          &quot;max_input_length&quot;: 50
        },
        &quot;fullname&quot;: {
          &quot;type&quot;: &quot;text&quot;
        }
      }
    }
  }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the above mapping we defined completion suggestor and we have used standard analyzer,it provides grammar based tokenization (based on the Unicode Text Segmentation algorithm, as specified in Unicode Standard Annex #29) and works well for most languages.&lt;/p&gt;

&lt;p&gt;Now we index few documents&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PUT sample/doc/1?refresh
{
  &quot;namesuggest&quot;: [
    {
      &quot;input&quot;: &quot;Kartheek Gummaluri&quot;,
      &quot;weight&quot;: 10
    }
  ],
  &quot;fullname&quot;: &quot;Kartheek Gummaluri&quot;
}

PUT sample/doc/2?refresh
{
  &quot;namesuggest&quot;: [
    {
      &quot;input&quot;: &quot;Kiran Sangita&quot;,
      &quot;weight&quot;: 6
    }
  ],
  &quot;fullname&quot;: &quot;Kiran Sangita&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So in the above document we have parameter called weight, so weight is used as relevancy tuning of search results.This helps us  which one needs to bubble up first.&lt;/p&gt;

&lt;p&gt;Now we will write a sample query to get better idea&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPOST &quot;http://localhost:9200/sample/_search?pretty&quot; -H 'Content-Type: application/json' -d'
{
  &quot;suggest&quot;: {
    &quot;namesuggest&quot;: {
      &quot;prefix&quot;: &quot;k&quot;,
      &quot;completion&quot;: {
        &quot;field&quot;: &quot;namesuggest&quot;
      }
    }
  }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So based on the above documents document-1 needs to be bubble up first because it has a weight of 10 where as the document -2 as weight 9.It will bubble up second.Please find results below.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;took&quot; : 8,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 5,
    &quot;successful&quot; : 5,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : 0,
    &quot;max_score&quot; : 0.0,
    &quot;hits&quot; : [ ]
  },
  &quot;suggest&quot; : {
    &quot;namesuggest&quot; : [
      {
        &quot;text&quot; : &quot;k&quot;,
        &quot;offset&quot; : 0,
        &quot;length&quot; : 1,
        &quot;options&quot; : [
          {
            &quot;text&quot; : &quot;Kartheek Gummaluri&quot;,
            &quot;_index&quot; : &quot;sample&quot;,
            &quot;_type&quot; : &quot;doc&quot;,
            &quot;_id&quot; : &quot;1&quot;,
            &quot;_score&quot; : 10.0,
            &quot;_source&quot; : {
              &quot;namesuggest&quot; : [
                {
                  &quot;input&quot; : &quot;Kartheek Gummaluri&quot;,
                  &quot;weight&quot; : 10
                }
              ],
              &quot;fullname&quot; : &quot;Kartheek Gummaluri&quot;
            }
          },
          {
            &quot;text&quot; : &quot;Kiran Sangita&quot;,
            &quot;_index&quot; : &quot;sample&quot;,
            &quot;_type&quot; : &quot;doc&quot;,
            &quot;_id&quot; : &quot;2&quot;,
            &quot;_score&quot; : 6.0,
            &quot;_source&quot; : {
              &quot;namesuggest&quot; : [
                {
                  &quot;input&quot; : &quot;Kiran Sangita&quot;,
                  &quot;weight&quot; : 6
                }
              ],
              &quot;fullname&quot; : &quot;Kiran Sangita&quot;
            }
          }
        ]
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thanks and stay tuned for further updates.&lt;/p&gt;</content><author><name></name></author><category term="ELasticSearch" /><summary type="html">In this post I will explain you the different types of suggestors that elasticsearch is providing and I will give you brief about “Completion Suggestor”.</summary></entry></feed>